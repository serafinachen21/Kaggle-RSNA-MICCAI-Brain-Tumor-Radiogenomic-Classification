{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('../input/d/workspace/all-submission-10-8/mysitepackages/kaggle/working/mysitepackages')"
   ],
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2021-10-14T17:42:40.142649Z",
     "iopub.execute_input": "2021-10-14T17:42:40.143307Z",
     "iopub.status.idle": "2021-10-14T17:42:40.148514Z",
     "shell.execute_reply.started": "2021-10-14T17:42:40.143270Z",
     "shell.execute_reply": "2021-10-14T17:42:40.147874Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys \n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sys.path.insert(0, 'furnace')\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n",
    "pytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\n",
    "monaipath = \"../input/rsna-dataset/monai/monai\"\n",
    "vitpath = \"../input/rsna-dataset/vit3d-pytorch-main/vit3d-pytorch-main\""
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2021-10-14T17:42:40.175180Z",
     "iopub.execute_input": "2021-10-14T17:42:40.175591Z",
     "iopub.status.idle": "2021-10-14T17:42:40.192452Z",
     "shell.execute_reply.started": "2021-10-14T17:42:40.175560Z",
     "shell.execute_reply": "2021-10-14T17:42:40.191806Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST  = False\n",
    "if(TEST):  \n",
    "    mri_types = ['FLAIR']\n",
    "else:\n",
    "    mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "    \n",
    "DROPOUT_RATE = 0.3\n",
    "SEED = 42\n",
    "\n",
    "GPU_NUM = 1\n",
    "SIZE = 256\n",
    "NUM_IMAGES = 64\n",
    "BATCH_SIZE = 4 * GPU_NUM\n",
    "N_EPOCHS = 8\n",
    "SEED = 42\n",
    "LEARNING_RATE = 0.0005\n",
    "LR_DECAY = 0.9\n",
    "num_slices = 1\n",
    "random_slices = False\n",
    "DROPOUT_RATE = DROPOUT_RATE\n",
    "MODEL = \"ViT3D\"\n",
    "modelfiles = ['../input/d/workspace/all-submission-10-8/model3d3407/model3d3407/ViT3D/FLAIR-e1-loss0.690-auc0.609-FOLD0.pth']\n",
    "\n",
    "\n",
    "sys.path.append(pytorch3dpath)\n",
    "sys.path.append(vitpath)\n",
    "sys.path.append(monaipath)\n",
    "\n",
    "\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "import monai\n",
    "from monai.networks.nets.densenet import DenseNet\n",
    "from monai.networks.nets.densenet import DenseNet121\n",
    "from monai.networks.nets.densenet import DenseNet169\n",
    "from monai.networks.nets.densenet import DenseNet201\n",
    "from monai.networks.nets.densenet import DenseNet264\n",
    "from monai.networks.nets.densenet import DenseNet264\n",
    "\n",
    "from monai.networks.nets.resnet import ResNet\n",
    "from monai.networks.nets.resnet import resnet34\n",
    "from monai.networks.nets.resnet import resnet50\n",
    "from monai.networks.nets.resnet import resnet101\n",
    "from monai.networks.nets.resnet import resnet152\n",
    "from monai.networks.nets.resnet import resnet200\n",
    "from monai.networks.nets.senet import SEResNet50\n",
    "from monai.networks.nets.senet import SEresnet101\n",
    "from monai.networks.nets.senet import SEresnet152\n",
    "from monai.networks.nets.senet import SEResNext50\n",
    "from monai.networks.nets.senet import SEResNext101\n",
    "\n",
    "from vit3d_pytorch import ViT3D\n",
    "from vit_pytorch.deepvit import DeepViT\n",
    "from vit_pytorch.t2t import T2TViT\n",
    "from vit_pytorch.cct import CCT\n",
    "from vit_pytorch.cross_vit import CrossViT\n",
    "from vit_pytorch.pit import PiT\n",
    "from vit_pytorch.levit import LeViT\n",
    "from vit_pytorch.cvt import CvT\n",
    "from vit_pytorch.twins_svt import TwinsSVT\n",
    "from vit_pytorch.nest import NesT\n",
    "\n",
    "from vit_pytorch.efficient import ViT\n",
    "from x_transformers import Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def load_dicom_image(path, img_size=SIZE):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if np.min(data)==np.max(data):\n",
    "        data = np.zeros((img_size,img_size))\n",
    "        return data\n",
    "    \n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data\n",
    "\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "\n",
    "def load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n",
    "    files = natural_sort(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"))\n",
    "    \n",
    "    every_nth = len(files) / num_imgs\n",
    "    indexes = [min(int(round(i*every_nth)), len(files)-1) for i in range(0,num_imgs)]\n",
    "    files_to_load = [files[i] for i in indexes]\n",
    "\n",
    "    if(split==\"train\" and random_slices):\n",
    "        if(every_nth>1):\n",
    "            files_to_load = natural_sort(random.sample(files, num_imgs))\n",
    "\n",
    "    if(num_slices>1):\n",
    "        import math\n",
    "        steps = int(math.floor(num_slices/2.0))\n",
    "        files_slices_to_load = [[files_to_load[j] for j in range(max(i - steps,0), min(i + steps + 1,NUM_IMAGES))] for i in range(len(indexes))]\n",
    "        img3d = np.stack([np.mean([load_dicom_image(f) for f in f_list],axis=0) for f_list in files_slices_to_load]).T\n",
    "    else:\n",
    "        img3d = np.stack([load_dicom_image(f) for f in files_to_load]).T \n",
    "    img3d = img3d - np.min(img3d)\n",
    "    if np.max(img3d) != 0:\n",
    "        img3d = img3d / np.max(img3d)\n",
    "    \n",
    "    return np.expand_dims(img3d,0)\n",
    "\n",
    "\n",
    "load_dicom_images_3d(\"00000\", mri_type=mri_types[0]).shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-14T17:42:41.964642Z",
     "iopub.execute_input": "2021-10-14T17:42:41.964922Z",
     "iopub.status.idle": "2021-10-14T17:42:42.839204Z",
     "shell.execute_reply.started": "2021-10-14T17:42:41.964893Z",
     "shell.execute_reply": "2021-10-14T17:42:42.838400Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "directory = 'model3d'+str(SEED)+'/'+MODEL\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "samples_to_exclude = [109, 123, 709]\n",
    "\n",
    "train_df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\n",
    "print(\"original shape\", train_df.shape)\n",
    "train_df = train_df[~train_df.BraTS21ID.isin(samples_to_exclude)]\n",
    "print(\"new shape\", train_df.shape)\n",
    "\n",
    "df_train, df_valid = sk_model_selection.train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED, \n",
    "    stratify=train_df[\"MGMT_value\"], \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, paths, targets=None, mri_type=None, split=\"train\"):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.mri_type = mri_type\n",
    "        self.split = split\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        scan_id = self.paths[index]\n",
    "        if self.targets is None:\n",
    "            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n",
    "        else:\n",
    "            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n",
    "            \n",
    "        if self.targets is None:\n",
    "            return {\"X\": data, \"id\": scan_id}\n",
    "        else:\n",
    "            return {\"X\": data, \"y\": torch.tensor(self.targets[index], dtype=torch.float)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        if(MODEL=='DenseNet'):\n",
    "            self.net = model = DenseNet(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "        elif(MODEL=='DenseNet121'):\n",
    "            self.net = model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "        elif(MODEL=='DenseNet169'):\n",
    "            self.net = model = DenseNet169(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "        elif(MODEL=='DenseNet201'):\n",
    "            self.net = model = DenseNet201(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "        elif(MODEL=='DenseNet264'):\n",
    "            self.net = model = DenseNet264(spatial_dims=3, in_channels=1, out_channels=1)\n",
    "        \n",
    "        if(MODEL=='resnet34'):\n",
    "            self.net = model = resnet34(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet50'):\n",
    "            self.net = model = resnet50(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet101'):\n",
    "            self.net = model = resnet101(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet152'):\n",
    "            self.net = model = resnet152(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet200'):\n",
    "            self.net = model = resnet200(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "\n",
    "        if(MODEL=='resnet34'):\n",
    "            self.net = model = resnet34(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet50'):\n",
    "            self.net = model = resnet50(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet101'):\n",
    "            self.net = model = resnet101(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet152'):\n",
    "            self.net = model = resnet152(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "        elif(MODEL=='resnet200'):\n",
    "            self.net = model = resnet200(spatial_dims=3,pretrained=False,n_input_channels=1)\n",
    "\n",
    "        if('efficientnet' in MODEL):\n",
    "            self.net = EfficientNet3D.from_name(MODEL, override_params={'num_classes': 2}, in_channels=1)\n",
    "\n",
    "        if(MODEL=='SEResNet50'):\n",
    "            self.net = SEResNet50(spatial_dims=3, in_channels=1)\n",
    "        elif(MODEL=='SEresnet101'):\n",
    "            self.net = SEresnet101(spatial_dims=3, in_channels=1)\n",
    "        elif(MODEL=='SEresnet152'):\n",
    "            self.net = SEresnet152(spatial_dims=3, in_channels=1)\n",
    "        elif(MODEL=='SEResNext50'):\n",
    "            self.net = SEResNext50(spatial_dims=3, in_channels=1)\n",
    "        elif(MODEL=='SEResNext101'):\n",
    "            self.net = SEResNext101(spatial_dims=3, in_channels=1)\n",
    "\n",
    "        if('ViT3D' in MODEL):\n",
    "            self.net = ViT3D(\n",
    "            image_size=(256, 256, NUM_IMAGES),\n",
    "            patch_size=32,\n",
    "            num_classes=1,\n",
    "            dim=1024,\n",
    "            depth=6,\n",
    "            heads=16,\n",
    "            mlp_dim=2048,\n",
    "            dropout=DROPOUT_RATE,\n",
    "            emb_dropout=DROPOUT_RATE\n",
    "            )\n",
    "            print('ViT3D')\n",
    "\n",
    "        if('SE' in MODEL):\n",
    "            n_features = self.net.last_linear.in_features\n",
    "            self.net.last_linear = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    ('dropout1', nn.Dropout(DROPOUT_RATE)),\n",
    "                    (\"out\", nn.Linear(in_features=n_features, out_features=1, bias=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        elif('resnet' in MODEL):\n",
    "            n_features = self.net.fc.in_features\n",
    "            self.net.fc = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    ('dropout1', nn.Dropout(DROPOUT_RATE)),\n",
    "                    (\"out\", nn.Linear(in_features=n_features, out_features=1, bias=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        elif('efficientnet' in MODEL):\n",
    "            n_features = self.net._fc.in_features\n",
    "            self.net._fc = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    ('dropout1', nn.Dropout(DROPOUT_RATE)),\n",
    "                    (\"out\", nn.Linear(in_features=n_features, out_features=1, bias=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        elif('Dense' in MODEL):\n",
    "            in_channels = self.net.class_layers[3].in_features\n",
    "            self.net.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    ('dropout1', nn.Dropout(DROPOUT_RATE)),\n",
    "                    (\"relu\", self.net.class_layers[0]),\n",
    "                    (\"pool\", self.net.class_layers[1]),\n",
    "                    (\"flatten\", self.net.class_layers[2]),\n",
    "                    (\"out\", self.net.class_layers[3]),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        bn_eps = 1e-5\n",
    "        bn_momentum = 0.1\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "        \n",
    "def build_model():\n",
    "    device_ids = [0, 1 , 2]\n",
    "    if(GPU_NUM==3):\n",
    "        model = torch.nn.DataParallel(Model(), device_ids=device_ids)\n",
    "    else:\n",
    "        model = Model()\n",
    "    return model    \n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=LR_DECAY)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.best_valid_score = .0\n",
    "        self.n_patience = 0\n",
    "        self.lastmodel = None\n",
    "        \n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "        self.val_auc = []\n",
    "        \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):      \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(valid_loss)\n",
    "            self.val_auc.append(valid_auc)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, valid_loss, valid_auc, valid_time\n",
    "            )\n",
    "\n",
    "            if self.best_valid_score < valid_auc: \n",
    "                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n",
    "                self.info_message(\n",
    "                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n",
    "                    self.best_valid_score, valid_auc, self.lastmodel\n",
    "                )\n",
    "                self.best_valid_score = valid_auc\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        # print(self.lr_scheduler.get_lr())\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].float().to(self.device)\n",
    "            # print(X.shape)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "                \n",
    "            loss.backward()\n",
    "\n",
    "            sum_loss += loss.detach().item()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            message = 'Train Step {}/{}, train_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n",
    "        # print(self.lr_scheduler.get_lr())\n",
    "        self.lr_scheduler.step()\n",
    "        \n",
    "        return sum_loss/len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                output = torch.sigmoid(self.model(batch[\"X\"].float().to(self.device)).squeeze(1))\n",
    "                loss = self.criterion(output, targets)\n",
    "                sum_loss += loss.detach().item()\n",
    "\n",
    "                y_all.extend(batch[\"y\"].tolist())\n",
    "                outputs_all.extend(output.tolist())\n",
    "\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        y_all = [1 if x > 0.5 else 0 for x in y_all]\n",
    "        auc = roc_auc_score(y_all, outputs_all)\n",
    "        \n",
    "        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path, loss, auc):\n",
    "        self.lastmodel = directory+'/'+f\"{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}-FOLD{FOLD}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            self.lastmodel,\n",
    "        )\n",
    "        \n",
    "    def display_plots(self, mri_type):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Training and Validation Loss\")\n",
    "        plt.plot(self.val_losses,label=\"val\")\n",
    "        plt.plot(self.train_losses,label=\"train\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"{}: Validation AUC-ROC\")\n",
    "        plt.plot(self.val_auc,label=\"val\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"AUC\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_mri_type(df_train, df_valid, mri_type):\n",
    "    if mri_type==\"all\":\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        for mri_type in mri_types:\n",
    "            df_train.loc[:,\"MRI_Type\"] = mri_type\n",
    "            train_list.append(df_train.copy())\n",
    "            df_valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "            valid_list.append(df_valid.copy())\n",
    "\n",
    "        df_train = pd.concat(train_list)\n",
    "        df_valid = pd.concat(valid_list)\n",
    "    else:\n",
    "        df_train.loc[:,\"MRI_Type\"] = mri_type\n",
    "        df_valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "\n",
    "    print(df_train.shape, df_valid.shape)\n",
    "    \n",
    "    train_data_retriever = Dataset(\n",
    "        df_train[\"BraTS21ID\"].values, \n",
    "        df_train[\"MGMT_value\"].values, \n",
    "        df_train[\"MRI_Type\"].values\n",
    "    )\n",
    "\n",
    "    valid_data_retriever = Dataset(\n",
    "        df_valid[\"BraTS21ID\"].values, \n",
    "        df_valid[\"MGMT_value\"].values,\n",
    "        df_valid[\"MRI_Type\"].values\n",
    "    )\n",
    "\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_data_retriever,\n",
    "        batch_size=BATCH_SIZE ,\n",
    "        shuffle=True,\n",
    "        num_workers=8 * GPU_NUM,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch_data.DataLoader(\n",
    "        valid_data_retriever, \n",
    "        batch_size=BATCH_SIZE ,\n",
    "        shuffle=False,\n",
    "        num_workers=8 * GPU_NUM,\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    )\n",
    "\n",
    "    history = trainer.fit(\n",
    "        N_EPOCHS, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        f\"{mri_type}\", \n",
    "        N_EPOCHS,\n",
    "    )\n",
    "\n",
    "    return trainer.lastmodel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "FOLD5 = True\n",
    "PREDICATION = False\n",
    "\n",
    "PREDICATION = PREDICATION\n",
    "def get_modelfiles():\n",
    "    modelfiles = ['','','',''] * 5\n",
    "    target_directory = f'./model3d{SEED}/'\n",
    "    file_list = os.listdir(target_directory)\n",
    "    best = [0,0,0,0] * 5\n",
    "    best_name = ['FLAIR','T1w-','T1wCE','T2w'] * 5\n",
    "    for file in file_list:\n",
    "            directory = target_directory+file\n",
    "            for every_file in os.listdir(directory):\n",
    "                for i in range(0,20):\n",
    "                    if(best_name[i] in every_file):\n",
    "                        if(('-FOLD'+str(i//4)) in every_file):\n",
    "                            best_now = float(every_file.split('auc')[1].split('.pth')[0].split('-')[0])\n",
    "                            modelfiles[i] = directory + '/' + every_file if best_now > best[i] else modelfiles[i]\n",
    "                            best[i] = best_now if best_now > best[i] else best[i]\n",
    "\n",
    "    return modelfiles\n",
    "\n",
    "if(PREDICATION):\n",
    "    modelfiles = get_modelfiles()\n",
    "    print(modelfiles)\n",
    "if not modelfiles:\n",
    "    modelfiles = []\n",
    "    if(FOLD5):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "        modelfiles = []\n",
    "        for n_fold, (train_index, valid_index) in enumerate(skf.split(train_df[[\"BraTS21ID\"]], train_df[\"MGMT_value\"])):\n",
    "            # if n_fold in [0]: # [0,1,2,3,4]\n",
    "            FOLD = str(n_fold)\n",
    "            df_train = train_df.iloc[train_index]\n",
    "            df_valid = train_df.iloc[valid_index]\n",
    "            modelfiles.extend([train_mri_type(df_train, df_valid, m) for m in mri_types])\n",
    "    else:\n",
    "        n_fold = 0\n",
    "        FOLD = str(n_fold)\n",
    "        df_train, df_valid = sk_model_selection.train_test_split(\n",
    "            train_df, \n",
    "            test_size=0.2, \n",
    "            random_state=SEED, \n",
    "            stratify=train_df[\"MGMT_value\"], \n",
    "        )\n",
    "\n",
    "        modelfiles = [train_mri_type(df_train, df_valid, m) for m in mri_types]\n",
    "    print(modelfiles)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-14T17:42:42.841124Z",
     "iopub.execute_input": "2021-10-14T17:42:42.841564Z",
     "iopub.status.idle": "2021-10-14T17:42:42.855685Z",
     "shell.execute_reply.started": "2021-10-14T17:42:42.841516Z",
     "shell.execute_reply": "2021-10-14T17:42:42.854873Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def predict(modelfile, df, mri_type, split):\n",
    "    print(\"Predict:\", modelfile, mri_type, df.shape)\n",
    "    df.loc[:,\"MRI_Type\"] = mri_type\n",
    "    data_retriever = Dataset(\n",
    "        df.index.values, \n",
    "        mri_type=df[\"MRI_Type\"].values,\n",
    "        split=split\n",
    "    )\n",
    "\n",
    "    data_loader = torch_data.DataLoader(\n",
    "        data_retriever,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "   \n",
    "    model = build_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    checkpoint = torch.load(modelfile)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    y_pred = []\n",
    "    ids = []\n",
    "\n",
    "    for e, batch in enumerate(data_loader,1):\n",
    "        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            tmp_pred = torch.sigmoid(model(batch[\"X\"].float().to(device)).squeeze(1)).cpu().numpy().squeeze()\n",
    "            if tmp_pred.size == 1:\n",
    "                y_pred.append(tmp_pred)\n",
    "            else:\n",
    "                y_pred.extend(tmp_pred.tolist())\n",
    "            ids.extend(batch[\"id\"].numpy().tolist())\n",
    "            \n",
    "    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n",
    "    preddf = preddf.set_index(\"BraTS21ID\")\n",
    "    return preddf\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\", index_col=\"BraTS21ID\")\n",
    "\n",
    "submission[\"MGMT_value\"] = 0\n",
    "\n",
    "import copy\n",
    "submission_list = []\n",
    "for i in range(0,5):\n",
    "    submission_list.append(copy.deepcopy(submission))\n",
    "    \n",
    "FOLDN = [0] * 5\n",
    "for m, mtype in zip(modelfiles, mri_types):\n",
    "    if(PREDICATION):\n",
    "        MODEL = m.split('/')[2]\n",
    "    pred = predict(m, submission, mtype, split=\"test\")\n",
    "    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n",
    "    for i in range(0,5):\n",
    "        if(('-FOLD'+str(i)) in m):\n",
    "            submission_list[i][\"MGMT_value\"] += pred[\"MGMT_value\"]\n",
    "            FOLDN[i] += 1\n",
    "            \n",
    "for i in range(0,5):\n",
    "    if(FOLDN[i]!=0):\n",
    "        submission_list[i] = submission_list[i]/FOLDN[i]\n",
    "        submission_list[i][\"MGMT_value\"].to_csv(\"/submission_\"+\"-FOLD\"+str(i)+\".csv\")\n",
    "print(time.time()-start)\n",
    "submission[\"MGMT_value\"] /= len(modelfiles)\n",
    "submission[\"MGMT_value\"].to_csv(\"/submission_\"+\".csv\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-14T17:54:02.620680Z",
     "iopub.execute_input": "2021-10-14T17:54:02.621093Z",
     "iopub.status.idle": "2021-10-14T17:54:22.536748Z",
     "shell.execute_reply.started": "2021-10-14T17:54:02.621052Z",
     "shell.execute_reply": "2021-10-14T17:54:22.535966Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  }
 ]
}